name: ü§ñ Automated Contract Monitoring

on:
  # Scheduled monitoring
  schedule:
    - cron: '0 */1 * * *'    # Every hour
    - cron: '0 9 * * *'      # Daily at 9AM UTC
    - cron: '0 8 * * 1'      # Weekly Monday 8AM UTC
  
  # Manual trigger for testing
  workflow_dispatch:
    inputs:
      monitoring_type:
        description: 'Type of monitoring to run'
        required: true
        default: 'manual'
        type: choice
        options:
        - manual
        - hourly
        - daily
        - weekly

jobs:
  # Hourly monitoring job
  hourly-monitoring:
    if: github.event.schedule == '0 */1 * * *' || github.event.inputs.monitoring_type == 'hourly'
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    steps:
    - name: üì• Checkout code
      uses: actions/checkout@v4
      
    - name: üêç Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'
        
    - name: üì¶ Install dependencies
      run: |
        cd backend
        pip install -r requirements.txt
        
    - name: ‚è∞ Run hourly monitoring
      run: |
        cd backend
        python3 -c "
        import os
        import sys
        import requests
        from datetime import datetime
        from dotenv import load_dotenv
        load_dotenv()
        
        print('‚è∞ HOURLY MONITORING - ' + datetime.now().strftime('%Y-%m-%d %H:%M:%S UTC'))
        print('=' * 50)
        
        # Quick Perplexity check for urgent announcements
        api_key = os.getenv('PERPLEXITY_API_KEY')
        if api_key:
            headers = {
                'Authorization': f'Bearer {api_key}',
                'Content-Type': 'application/json'
            }
            
            payload = {
                'model': 'llama-3.1-sonar-small-128k-online',
                'messages': [{
                    'role': 'user', 
                    'content': '''Find URGENT government contract announcements from the last 2 hours.
                    
                    Search for:
                    - Breaking contract awards over \$10M
                    - Emergency procurement notices
                    - Time-sensitive RFP releases with short deadlines
                    
                    Only return if genuinely urgent. Format as brief summary.'''
                }],
                'max_tokens': 200,
                'temperature': 0.1,
                'search_domain_filter': ['sam.gov', 'usaspending.gov', 'defense.gov']
            }
            
            try:
                response = requests.post(
                    'https://api.perplexity.ai/chat/completions',
                    headers=headers,
                    json=payload,
                    timeout=30
                )
                
                if response.status_code == 200:
                    data = response.json()
                    content = data['choices'][0]['message']['content']
                    
                    # Check if urgent content found
                    urgent_keywords = ['urgent', 'breaking', 'announced', 'awarded', 'emergency']
                    if any(word in content.lower() for word in urgent_keywords):
                        print('üö® URGENT CONTRACT ANNOUNCEMENT DETECTED!')
                        print(f'üìÑ {content[:300]}...')
                        
                        # Could send Slack/email notification here
                        print('üìß Alert notifications would be sent here')
                    else:
                        print('‚úÖ No urgent announcements in last 2 hours')
                else:
                    print(f'‚ö†Ô∏è Perplexity API error: {response.status_code}')
                    
            except Exception as e:
                print(f'‚ùå Hourly check failed: {e}')
        else:
            print('‚ö†Ô∏è PERPLEXITY_API_KEY not configured')
        
        print('‚è∞ Hourly monitoring complete')
        "
      env:
        PERPLEXITY_API_KEY: ${{ secrets.PERPLEXITY_API_KEY }}
        SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
        SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}

  # Daily monitoring job  
  daily-monitoring:
    if: github.event.schedule == '0 9 * * *' || github.event.inputs.monitoring_type == 'daily'
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    steps:
    - name: üì• Checkout code
      uses: actions/checkout@v4
      
    - name: üêç Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'
        
    - name: üì¶ Install dependencies
      run: |
        cd backend
        pip install -r requirements.txt
        
    - name: üìÖ Run daily discovery
      run: |
        cd backend
        python3 perplexity_live_discovery.py
      env:
        PERPLEXITY_API_KEY: ${{ secrets.PERPLEXITY_API_KEY }}
        SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
        SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
        FIRECRAWL_API_KEY: ${{ secrets.FIRECRAWL_API_KEY }}
        SAM_GOV_API_KEY: ${{ secrets.SAM_GOV_API_KEY }}
        
    - name: üî• Run daily Firecrawl scraping
      run: |
        cd backend
        python3 -c "
        import os
        import sys
        import requests
        import time
        from datetime import datetime
        from dotenv import load_dotenv
        load_dotenv()
        
        print('üî• DAILY FIRECRAWL SCRAPING - ' + datetime.now().strftime('%Y-%m-%d %H:%M:%S UTC'))
        print('=' * 50)
        
        api_key = os.getenv('FIRECRAWL_API_KEY')
        if not api_key:
            print('‚ö†Ô∏è FIRECRAWL_API_KEY not configured')
            sys.exit(0)
        
        # Key government pages to scrape daily
        targets = [
            {
                'name': 'GSA News',
                'url': 'https://www.gsa.gov/about-us/newsroom/news-releases'
            },
            {
                'name': 'DoD Contracts', 
                'url': 'https://www.defense.gov/News/Contracts/'
            }
        ]
        
        headers = {
            'Authorization': f'Bearer {api_key}',
            'Content-Type': 'application/json'
        }
        
        total_contracts_found = 0
        
        for target in targets:
            try:
                print(f'üì° Scraping {target[\"name\"]}...')
                
                payload = {
                    'url': target['url'],
                    'formats': ['markdown'],
                    'onlyMainContent': True
                }
                
                response = requests.post(
                    'https://api.firecrawl.dev/v0/scrape',
                    headers=headers,
                    json=payload,
                    timeout=30
                )
                
                if response.status_code == 200:
                    data = response.json()
                    content = data.get('data', {}).get('markdown', '')
                    
                    # Count contract indicators
                    contract_words = ['contract', 'award', 'million', 'billion', 'solicitation', 'rfp']
                    contract_count = sum(content.lower().count(word) for word in contract_words)
                    total_contracts_found += contract_count
                    
                    print(f'   ‚úÖ {target[\"name\"]}: {len(content):,} chars, {contract_count} contract mentions')
                else:
                    print(f'   ‚ùå {target[\"name\"]}: Error {response.status_code}')
                
                # Rate limiting
                time.sleep(3)
                
            except Exception as e:
                print(f'   ‚ùå {target[\"name\"]} failed: {e}')
        
        print(f'üéØ Daily scraping complete: {total_contracts_found} contract mentions found')
        "
      env:
        FIRECRAWL_API_KEY: ${{ secrets.FIRECRAWL_API_KEY }}

  # Weekly intelligence job
  weekly-intelligence:
    if: github.event.schedule == '0 8 * * 1' || github.event.inputs.monitoring_type == 'weekly'
    runs-on: ubuntu-latest
    timeout-minutes: 45
    
    steps:
    - name: üì• Checkout code
      uses: actions/checkout@v4
      
    - name: üêç Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'
        
    - name: üì¶ Install dependencies
      run: |
        cd backend
        pip install -r requirements.txt
        
    - name: üìä Generate weekly market intelligence
      run: |
        cd backend
        python3 -c "
        import os
        import sys
        import requests
        from datetime import datetime
        from dotenv import load_dotenv
        load_dotenv()
        
        print('üìä WEEKLY MARKET INTELLIGENCE - ' + datetime.now().strftime('%Y-%m-%d %H:%M:%S UTC'))
        print('=' * 50)
        
        api_key = os.getenv('PERPLEXITY_API_KEY')
        if not api_key:
            print('‚ö†Ô∏è PERPLEXITY_API_KEY not configured')
            sys.exit(0)
        
        headers = {
            'Authorization': f'Bearer {api_key}',
            'Content-Type': 'application/json'
        }
        
        # Weekly market analysis
        analysis_queries = [
            {
                'name': 'Market Trends',
                'prompt': '''Analyze government contracting market trends for this week.
                Focus on: 1) Highest spending agencies 2) Hot sectors 3) Major awards
                4) Upcoming solicitations 5) Small business opportunities'''
            },
            {
                'name': 'Technology Predictions',
                'prompt': '''Predict upcoming government technology contracts in next 30 days.
                Focus on: 1) AI/ML opportunities 2) Cybersecurity needs 3) Cloud migrations
                4) Data analytics projects 5) IT modernization initiatives'''
            },
            {
                'name': 'Defense Opportunities',
                'prompt': '''Analyze defense contracting opportunities this week.
                Focus on: 1) New DoD solicitations 2) R&D opportunities 3) Major platforms
                4) International sales 5) Emerging technologies'''
            }
        ]
        
        for query in analysis_queries:
            try:
                print(f'üß† Generating {query[\"name\"]} analysis...')
                
                payload = {
                    'model': 'llama-3.1-sonar-small-128k-online',
                    'messages': [{'role': 'user', 'content': query['prompt']}],
                    'max_tokens': 400,
                    'temperature': 0.1,
                    'search_domain_filter': ['sam.gov', 'usaspending.gov', 'defense.gov', 'gsa.gov']
                }
                
                response = requests.post(
                    'https://api.perplexity.ai/chat/completions',
                    headers=headers,
                    json=payload,
                    timeout=60
                )
                
                if response.status_code == 200:
                    data = response.json()
                    analysis = data['choices'][0]['message']['content']
                    citations = data.get('citations', [])
                    
                    print(f'   ‚úÖ {query[\"name\"]}: {len(analysis)} chars, {len(citations)} sources')
                    print(f'   üìÑ Preview: {analysis[:100]}...')
                else:
                    print(f'   ‚ùå {query[\"name\"]}: Error {response.status_code}')
                
            except Exception as e:
                print(f'   ‚ùå {query[\"name\"]} failed: {e}')
        
        print('üìä Weekly intelligence generation complete')
        "
      env:
        PERPLEXITY_API_KEY: ${{ secrets.PERPLEXITY_API_KEY }}

  # Manual monitoring job
  manual-monitoring:
    if: github.event.inputs.monitoring_type == 'manual'
    runs-on: ubuntu-latest
    timeout-minutes: 20
    
    steps:
    - name: üì• Checkout code
      uses: actions/checkout@v4
      
    - name: üêç Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'
        
    - name: üì¶ Install dependencies
      run: |
        cd backend
        pip install -r requirements.txt
        
    - name: üîß Run manual monitoring demo
      run: |
        cd backend
        python3 demo_live_monitoring.py
      env:
        PERPLEXITY_API_KEY: ${{ secrets.PERPLEXITY_API_KEY }}
        FIRECRAWL_API_KEY: ${{ secrets.FIRECRAWL_API_KEY }}
        SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
        SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}

  # Health check job
  health-check:
    runs-on: ubuntu-latest
    timeout-minutes: 5
    
    steps:
    - name: üè• Check system health
      run: |
        echo "üè• SYSTEM HEALTH CHECK - $(date)"
        echo "=" * 40
        
        # Check frontend
        echo "üåê Testing frontend..."
        curl -s -o /dev/null -w "Frontend: %{http_code}\n" https://frontend-73o5kxpn6-jacobs-projects-cf4c7bdb.vercel.app
        
        # Check backend  
        echo "üîß Testing backend..."
        curl -s -o /dev/null -w "Backend: %{http_code}\n" https://backend-bn42qj3a9-jacobs-projects-cf4c7bdb.vercel.app/api/health
        
        # Check API endpoints
        echo "üìä Testing opportunities API..."
        curl -s -o /dev/null -w "Opportunities API: %{http_code}\n" https://backend-bn42qj3a9-jacobs-projects-cf4c7bdb.vercel.app/api/opportunities
        
        echo "‚úÖ Health check complete"